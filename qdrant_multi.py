import time
from typing import List
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# âœ… Qdrant ì„¤ì •
qdrant_client = QdrantClient(host="localhost", port=6333)
collection_name = "article_2025_image_test"

# âœ… í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
model = SentenceTransformer("nlpai-lab/KURE-v1")

# âœ… í•„í„°ë§ í•„ë“œ ëª©ë¡
KEYWORD_FILTER_FIELDS = [
    "title_original", "organization", "reporter",
    "year", "month", "date_day", "date_weekday", "topic", "content"
]

# âœ… ë²¡í„° ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ (ì „ì²´ ëŒ€ìƒ)
def semantic_vector_search(question: str, top_k: int = 10):
    print(f"\nğŸ§  [ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰] ì§ˆë¬¸: {question}")
    start = time.time()

    try:
        query_vector = model.encode(question)
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            limit=top_k,
            with_payload=True,
            score_threshold=0.5
        )
    except Exception as e:
        print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

    documents = []
    for hit in results:
        payload = hit.payload
        documents.append({
            "id": hit.id,
            "ì œëª©": payload.get("title_original", ""),
            "ì–¸ë¡ ì‚¬": payload.get("organization", ""),
            "ê¸°ì": payload.get("reporter", ""),
            "ë‚ ì§œ": f"{payload.get('year', '----')}-{payload.get('month', '--')}-{payload.get('date_day', '--')} ({payload.get('date_weekday', '-')})",
            "ì£¼ì œ": payload.get("topic", ""),
            "ìš”ì•½": payload.get("summary", ""),
            "URL": payload.get("url", ""),
            "Image_url":hit.payload.get("main_image_url", ""),
            "ë³¸ë¬¸": payload.get("content", ""),
            "score": round(hit.score, 5) if hasattr(hit, "score") else 0.0
        })

    print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - start:.2f}ì´ˆ) â†’ ê²°ê³¼ {len(documents)}ê±´")
    return documents


def search_qdrant_metadata_smart(keywords: List[str], top_k_per_keyword: int = 50):
    print(f"\nğŸ“‹ [ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰] í‚¤ì›Œë“œ ëª©ë¡: {keywords}")

    year_val = next((int(k) for k in keywords if k.isdigit() and len(k) == 4 and 1900 <= int(k) <= 2100), None)
    month_val = next((int(k) for k in keywords if k.isdigit() and 1 <= int(k) <= 12), None)
    day_val = next((int(k) for k in keywords if k.isdigit() and 1 <= int(k) <= 31), None)

    date_conditions = []
    if year_val: date_conditions.append(FieldCondition(key="year", match=MatchValue(value=year_val)))
    if month_val: date_conditions.append(FieldCondition(key="month", match=MatchValue(value=month_val)))
    if day_val: date_conditions.append(FieldCondition(key="date_day", match=MatchValue(value=day_val)))

    keyword_conditions = []
    for keyword in keywords:
        if keyword.isdigit() and (keyword == str(year_val) or keyword == str(month_val) or keyword == str(day_val)):
            continue  # ë‚ ì§œë¡œ ì´ë¯¸ ì²˜ë¦¬ëœ ê°’ì€ ì œì™¸
        keyword_conditions.extend(
            FieldCondition(key=field, match=MatchValue(value=keyword))
            for field in KEYWORD_FILTER_FIELDS
        )

    try:
        if date_conditions:
            if keyword_conditions:
                query_filter = Filter(must=[
                    Filter(must=date_conditions),
                    Filter(should=keyword_conditions)
                ])
            else:
                query_filter = Filter(must=date_conditions)
        else:
            query_filter = Filter(should=keyword_conditions)

        result = qdrant_client.query_points(
            collection_name=collection_name,
            query_filter=query_filter,
            limit=top_k_per_keyword,
            with_payload=True
        )
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

    documents = []
    for point in result.points:
        payload = point.payload
        documents.append({
            "id": point.id,
            "ì œëª©": payload.get("title_original", ""),
            "ì–¸ë¡ ì‚¬": payload.get("organization", ""),
            "ê¸°ì": payload.get("reporter", ""),
            "ë‚ ì§œ": f"{payload.get('year', '----')}-{payload.get('month', '--')}-{payload.get('date_day', '--')} ({payload.get('date_weekday', '-')})",
            "ì£¼ì œ": payload.get("topic", ""),
            "ìš”ì•½": payload.get("summary", ""),
            "URL": payload.get("url", ""),
            "ë³¸ë¬¸": payload.get("content", "")
        })

    print(f"âœ… ì´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(documents)}")
    return documents

# âœ… í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§
def search_qdrant_metadata_by_keywords(keywords: List[str], top_k_per_keyword: int = 50):
    print(f"\nğŸ“‹ [í‚¤ì›Œë“œ ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰] í‚¤ì›Œë“œ ëª©ë¡: {keywords}")
    matched_ids = set()
    documents_map = {}

    for keyword in keywords:
        print(f"ğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")

        try:
            conditions = [
                FieldCondition(key=field, match=MatchValue(value=keyword))
                for field in KEYWORD_FILTER_FIELDS
            ]
            query_filter = Filter(should=conditions)

            result = qdrant_client.query_points(
                collection_name=collection_name,
                query_filter=query_filter,
                limit=top_k_per_keyword,
                with_payload=True
            )
        except Exception as e:
            print(f"âŒ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            continue

        for point in result.points:
            pid = point.id
            if pid not in matched_ids:
                matched_ids.add(pid)
                payload = getattr(point, 'payload', None)
                if payload:
                    documents_map[pid] = {
                        "id": pid,
                        "ì œëª©": payload.get("title_original", ""),
                        "ì–¸ë¡ ì‚¬": payload.get("organization", ""),
                        "ê¸°ì": payload.get("reporter", ""),
                        "ë‚ ì§œ": f"{payload.get('year', '----')}-{payload.get('month', '--')}-{payload.get('date_day', '--')} ({payload.get('date_weekday', '-')})",
                        "ì£¼ì œ": payload.get("topic", ""),
                        "ìš”ì•½": payload.get("summary", ""),
                        "URL": payload.get("url", ""),
                        "ë³¸ë¬¸": payload.get("content", "")
                    }

    print(f"âœ… ì´ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(documents_map)}")
    return list(documents_map.values())

# âœ… í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„° + ì˜ë¯¸ ê¸°ë°˜ ì¬ì •ë ¬
def keyword_then_semantic_rerank(question: str, keywords: List[str], top_k: int = 5):
    print(f"\nğŸ” [ì¢…í•© ê²€ìƒ‰ ì‹œì‘] ì§ˆë¬¸: '{question}' | í‚¤ì›Œë“œ í•„í„°: {keywords}")

    metadata_results = search_qdrant_metadata_smart(keywords, top_k_per_keyword=50)

    if not metadata_results:
        print("âš ï¸ í‚¤ì›Œë“œ ê²°ê³¼ ì—†ìŒ â†’ ì „ì²´ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ fallback")
        return semantic_vector_search(question, top_k=top_k)

    print("ğŸ’¡ í‚¤ì›Œë“œ ê²°ê³¼ ì¡´ì¬ â†’ ì˜ë¯¸ ê¸°ë°˜ ì¬ì •ë ¬ ìˆ˜í–‰ ì¤‘...")
    query_vector = model.encode(question)
    contents = [doc["ë³¸ë¬¸"] for doc in metadata_results]
    doc_vectors = model.encode(contents, batch_size=32)

    similarities = cosine_similarity([query_vector], doc_vectors)[0]

    reranked = []
    for i, doc in enumerate(metadata_results):
        score = float(similarities[i])
        if score < 0.35:
            continue
        doc["score"] = round(score, 5)
        reranked.append(doc)

    sorted_results = sorted(reranked, key=lambda x: x["score"], reverse=True)
    print(f"âœ… ì¢…í•© ê²€ìƒ‰ ì™„ë£Œ: {len(sorted_results)}ê±´ ì¤‘ ìƒìœ„ {top_k}ê°œ ë°˜í™˜")
    return sorted_results[:top_k]
