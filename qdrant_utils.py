import time, gc, torch
from typing import List, Tuple, Dict, Set
from concurrent.futures import ThreadPoolExecutor
from qdrant_client import QdrantClient
from qdrant_client.models import MatchValue, Filter, FieldCondition
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# âœ… Qdrant ì„¤ì •
qdrant_client = QdrantClient(host="localhost", port=6333)
collection_name = "article_2025_image_test"

# âœ… í•œêµ­ì–´ ìž„ë² ë”© ëª¨ë¸
model = SentenceTransformer("nlpai-lab/KURE-v1")

# âœ… VRAM ì²­ì†Œ í¬í•¨ ìž„ë² ë”© í•¨ìˆ˜ (query ì „ìš©)
def encode_and_clear(texts, **kwargs):
    vectors = model.encode(texts, **kwargs)
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()
    return vectors

# âœ… ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰ í•„ë“œ
KEYWORD_FILTER_FIELDS = [
    "title_original", "organization", "reporter",
    "topic", "content"
]

# âœ… ë‹¨ì¼ í‚¤ì›Œë“œ ê²€ìƒ‰
def keyword_search_single(keyword: str, top_k: int = 50) -> Tuple[Set, Dict, str]:
    keyword_type = "none"
    query_filter = None

    if keyword.isdigit():
        val_str = keyword
        val = int(keyword)

        if len(keyword) == 4 and 1900 <= val <= 2100:
            keyword_type = "year"
            query_filter = Filter(must=[FieldCondition(key="year", match=MatchValue(value=val_str))])
        elif 1 <= val <= 12:
            keyword_type = "month"
            query_filter = Filter(must=[FieldCondition(key="month", match=MatchValue(value=val_str))])
        else:
            return set(), {}, keyword_type
    else:
        query_filter = Filter(
            should=[FieldCondition(key=field, match=MatchValue(value=keyword))
                    for field in KEYWORD_FILTER_FIELDS]
        )

    result = qdrant_client.query_points(
        collection_name=collection_name,
        query_filter=query_filter,
        limit=top_k,
        with_payload=True,
        with_vectors=True   # âœ… ë²¡í„°ë„ ê°™ì´ ê°€ì ¸ì˜¤ê¸°
    )

    ids = {p.id for p in result.points}
    payloads = {p.id: {"payload": p.payload, "vector": p.vector} for p in result.points}
    return ids, payloads, keyword_type

# âœ… ë³‘ë ¬ í‚¤ì›Œë“œ ê²€ìƒ‰
def search_qdrant_metadata_parallel(keywords: List[str], top_k_per_keyword: int = 50):
    all_payloads = {}
    keyword_results = {}
    keyword_types = {}

    with ThreadPoolExecutor(max_workers=len(keywords)) as executor:
        futures = {executor.submit(keyword_search_single, kw, top_k_per_keyword): kw for kw in keywords}
        for future in futures:
            ids, payloads, kw_type = future.result()
            kw = futures[future]
            keyword_results[kw] = ids
            keyword_types[kw] = kw_type
            all_payloads.update(payloads)

    return keyword_results, all_payloads, keyword_types

# âœ… ë‚ ì§œ(MUST) + ì˜ë¯¸ê²€ìƒ‰ ìž¬ì •ë ¬
def keyword_then_semantic_rerank(question: str, keywords: List[str], top_k: int = 5):
    keyword_results, all_payloads, keyword_types = search_qdrant_metadata_parallel(keywords, top_k_per_keyword=200)

    date_sets = [ids for kw, ids in keyword_results.items() if keyword_types[kw] in ("year", "month")]
    date_intersection = set.intersection(*date_sets) if date_sets else None

    normal_sets = [ids for kw, ids in keyword_results.items() if keyword_types[kw] == "none"]
    normal_union = set.union(*normal_sets) if normal_sets else None

    if date_intersection and normal_union:
        final_ids = date_intersection & normal_union
    elif date_intersection:
        final_ids = date_intersection
    elif normal_union:
        final_ids = normal_union
    else:
        final_ids = set()

    # âœ… Qdrantì—ì„œ ë°”ë¡œ ì˜ë¯¸ê²€ìƒ‰ (ë‚ ì§œ í•„í„° ìžˆëŠ” ê²½ìš°)
    if date_intersection:
        print(f"âš¡ ë‚ ì§œ í•„í„° ì ìš©ë¨ â†’ Qdrantì—ì„œ ë²¡í„°ê²€ìƒ‰ ë°”ë¡œ ì‹¤í–‰")
        query_vector = encode_and_clear([question])[0]
        must_conditions = []
        for kw, kw_type in keyword_types.items():
            if kw_type == "year":
                must_conditions.append(FieldCondition(key="year", match=MatchValue(value=kw)))
            elif kw_type == "month":
                must_conditions.append(FieldCondition(key="month", match=MatchValue(value=kw)))
        filter_query = Filter(must=must_conditions)
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=filter_query,
            limit=top_k,
            with_payload=True
        )
        return [
            {
                "id": hit.id,
                "ì œëª©": hit.payload.get("title_original", ""),
                "ê¸°ìž": hit.payload.get("reporter", ""),
                "ë‚ ì§œ": f"{hit.payload.get('year', '----')}-{hit.payload.get('month', '--')}-{hit.payload.get('date_day', '--')}",
                "ì£¼ì œ": hit.payload.get("topic", ""),
                "URL": hit.payload.get("url", ""),
                "Image_url": hit.payload.get("main_image_url", ""),
                "ë³¸ë¬¸": hit.payload.get("content", ""),
                "score": round(hit.score, 5)
            }
            for hit in results
        ]

    # âœ… ë¡œì»¬ ìž¬ëž­í‚¹ (ë²¡í„°ëŠ” Qdrantì—ì„œ êº¼ëƒ„)
    if not final_ids:
        print("âš ï¸ í•„í„° ê²°ê³¼ ì—†ìŒ â†’ ì „ì²´ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ fallback")
        return semantic_vector_search(question, top_k=top_k)

    print(f"ðŸ’¡ í•„í„°ë§ëœ ë¬¸ì„œ {len(final_ids)}ê±´ â†’ ë¡œì»¬ ì˜ë¯¸ê²€ìƒ‰ ìž¬ì •ë ¬")
    query_vector = encode_and_clear([question])[0]

    doc_vectors = [all_payloads[pid]["vector"] for pid in final_ids]
    similarities = cosine_similarity([query_vector], doc_vectors)[0]

    reranked = []
    for pid, score in zip(final_ids, similarities):
        payload = all_payloads[pid]["payload"]
        reranked.append({
            "id": pid,
            "ì œëª©": payload.get("title_original", ""),
            "ê¸°ìž": payload.get("reporter", ""),
            "ë‚ ì§œ": f"{payload.get('year', '----')}-{payload.get('month', '--')}-{payload.get('date_day', '--')}",
            "ì£¼ì œ": payload.get("topic", ""),
            "URL": payload.get("url", ""),
            "Image_url": payload.get("main_image_url", ""),
            "ë³¸ë¬¸": payload.get("content", ""),
            "score": round(float(score), 5)
        })

    return sorted(reranked, key=lambda x: x["score"], reverse=True)[:top_k]

# âœ… ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ (Qdrant ë²¡í„° ì§ì ‘ í™œìš©)
def semantic_vector_search(question: str, top_k: int = 10):
    query_vector = encode_and_clear([question])[0]
    results = qdrant_client.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=top_k,
        with_payload=True
    )
    return [
        {
            "id": hit.id,
            "ì œëª©": hit.payload.get("title_original", ""),
            "ê¸°ìž": hit.payload.get("reporter", ""),
            "ë‚ ì§œ": f"{hit.payload.get('year', '----')}-{hit.payload.get('month', '--')}-{hit.payload.get('date_day', '--')}",
            "ì£¼ì œ": hit.payload.get("topic", ""),
            "URL": hit.payload.get("url", ""),
            "Image_url": hit.payload.get("main_image_url", ""),
            "ë³¸ë¬¸": hit.payload.get("content", ""),
            "score": round(hit.score, 5)
        }
        for hit in results
    ]
